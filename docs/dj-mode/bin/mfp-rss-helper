#!/usr/bin/env python3
# /// script
# requires-python = ">=3.10"
# ///
"""
mfp-rss-helper - Music For Programming RSS helper

Fetches and caches the MFP RSS feed, providing episode URLs by number.
Uses smart caching: tries to fetch fresh data, falls back to cache if offline.

Usage:
    mfp-rss-helper <episode-number>    Get URL for episode
    mfp-rss-helper filename <episode>  Get RSS-based filename for episode
    mfp-rss-helper --list              List all episodes (deprecated, use 'list')
    mfp-rss-helper --refresh           Force refresh cache
    mfp-rss-helper list [options]      List episodes with chapter/local status

List options:
    --format=human|tsv    Output format (default: human)
    --urls                Include download URLs
    --all                 Show all episodes (default: only those with chapters)
    --verbose             Show CUE/FFmeta breakdown separately
"""

import sys
import xml.etree.ElementTree as ET
from pathlib import Path
from urllib.request import urlopen
from urllib.error import URLError
import re
import argparse

RSS_URL = "https://musicforprogramming.net/rss.xml"
CACHE_DIR = Path.home() / ".voicemode" / "music-for-programming"
CACHE_FILE = CACHE_DIR / "rss.xml"


def fetch_rss(force_refresh: bool = False) -> str:
    """Fetch RSS feed with smart caching.

    Strategy:
    1. Try to fetch fresh RSS from the network
    2. If successful, update the cache
    3. If network fails and cache exists, use cache
    4. If network fails and no cache, raise error
    """
    CACHE_DIR.mkdir(parents=True, exist_ok=True)

    if not force_refresh:
        # Try network fetch first
        try:
            with urlopen(RSS_URL, timeout=10) as response:
                content = response.read().decode("utf-8")
                # Update cache on successful fetch
                CACHE_FILE.write_text(content)
                return content
        except (URLError, TimeoutError):
            # Network failed, try cache
            if CACHE_FILE.exists():
                return CACHE_FILE.read_text()
            raise RuntimeError(
                f"Cannot fetch RSS feed and no cache exists at {CACHE_FILE}"
            )
    else:
        # Force refresh - must succeed
        try:
            with urlopen(RSS_URL, timeout=10) as response:
                content = response.read().decode("utf-8")
                CACHE_FILE.write_text(content)
                return content
        except (URLError, TimeoutError) as e:
            raise RuntimeError(f"Cannot fetch RSS feed: {e}")


def parse_episodes(rss_content: str) -> dict[int, dict]:
    """Parse RSS content and return dict of episode_num -> episode info."""
    episodes = {}

    root = ET.fromstring(rss_content)

    for item in root.findall(".//item"):
        enclosure = item.find("enclosure")
        if enclosure is None:
            continue

        url = enclosure.get("url", "")
        title = item.findtext("title", "")

        # Extract episode number from URL
        # Pattern: music_for_programming_76-material_object.mp3
        match = re.search(r"music_for_programming_(\d+)-", url)
        if match:
            episode_num = int(match.group(1))
            episodes[episode_num] = {
                "url": url,
                "title": title,
                "length": enclosure.get("length", ""),
            }

    return episodes


def get_episode_url(episode_num: int) -> str:
    """Get URL for a specific episode number."""
    rss_content = fetch_rss()
    episodes = parse_episodes(rss_content)

    if episode_num not in episodes:
        available = sorted(episodes.keys())
        raise ValueError(
            f"Episode {episode_num} not found. "
            f"Available: {available[0]}-{available[-1]}"
        )

    return episodes[episode_num]["url"]


def get_filename_base_from_url(url: str) -> str:
    """Extract the filename base (without extension) from an RSS URL.

    Example: music_for_programming_49-julien_mier.mp3 -> music_for_programming_49-julien_mier
    """
    match = re.search(r'(music_for_programming_\d+-.+)\.mp3', url)
    if match:
        return match.group(1)
    raise ValueError(f"Cannot extract filename from URL: {url}")


def get_filename_base(episode_num: int) -> str:
    """Get the filename base (without extension) for an episode from RSS.

    Returns the canonical filename as defined in the RSS feed URL.
    Example: music_for_programming_49-julien_mier
    """
    url = get_episode_url(episode_num)
    return get_filename_base_from_url(url)


def list_episodes() -> None:
    """List all available episodes (deprecated)."""
    rss_content = fetch_rss()
    episodes = parse_episodes(rss_content)

    print(f"Music For Programming - {len(episodes)} episodes available\n")

    for num in sorted(episodes.keys()):
        ep = episodes[num]
        # Extract curator name from URL
        match = re.search(r"music_for_programming_\d+-(.+)\.mp3", ep["url"])
        curator = match.group(1).replace("_", " ") if match else "unknown"
        print(f"  {num:3d}  {curator}")


def check_chapter_files(url: str) -> dict:
    """Check for local CUE and FFmeta chapter files.

    Uses RSS-based filename from URL.
    Returns dict with keys: has_cue, has_ffmeta, has_chapters (either exists)
    """
    filename_base = get_filename_base_from_url(url)
    cue_file = CACHE_DIR / f"{filename_base}.cue"
    ffmeta_file = CACHE_DIR / f"{filename_base}.ffmeta"

    has_cue = cue_file.exists()
    has_ffmeta = ffmeta_file.exists()

    return {
        "has_cue": has_cue,
        "has_ffmeta": has_ffmeta,
        "has_chapters": has_cue or has_ffmeta,
    }


def check_local_mp3(url: str) -> bool:
    """Check if local MP3 file exists."""
    filename_base = get_filename_base_from_url(url)
    mp3_file = CACHE_DIR / f"{filename_base}.mp3"
    return mp3_file.exists()


def list_episodes_detailed(
    format_type: str = "human",
    include_urls: bool = False,
    show_all: bool = False,
    verbose: bool = False,
) -> None:
    """List episodes with chapter and local status.

    Args:
        format_type: "human" for columnized output, "tsv" for machine-readable
        include_urls: Include download URLs in output
        show_all: Show all episodes (default: only those with chapters)
        verbose: Show CUE/FFmeta breakdown separately
    """
    rss_content = fetch_rss()
    episodes = parse_episodes(rss_content)

    # Build episode list with status
    episode_list = []
    for num in sorted(episodes.keys(), reverse=True):
        ep = episodes[num]

        # Extract curator name from URL
        match = re.search(r"music_for_programming_\d+-(.+)\.mp3", ep["url"])
        curator = match.group(1).replace("_", " ") if match else "unknown"

        # Check local status using RSS-based filename
        chapter_info = check_chapter_files(ep["url"])
        has_mp3 = check_local_mp3(ep["url"])

        episode_list.append({
            "number": num,
            "curator": curator,
            "url": ep["url"],
            "has_chapters": chapter_info["has_chapters"],
            "has_cue": chapter_info["has_cue"],
            "has_ffmeta": chapter_info["has_ffmeta"],
            "has_mp3": has_mp3,
        })

    # Filter if not showing all
    if not show_all:
        episode_list = [ep for ep in episode_list if ep["has_chapters"]]

    if format_type == "tsv":
        _output_tsv(episode_list, include_urls, verbose)
    else:
        _output_human(episode_list, include_urls, verbose, show_all)


def _output_human(
    episodes: list,
    include_urls: bool,
    verbose: bool,
    show_all: bool,
) -> None:
    """Output episodes in human-readable columnized format."""
    if not episodes:
        if show_all:
            print("No episodes found in RSS feed.")
        else:
            print("No episodes with complete chapter files.")
            print("Use --all to see all episodes from RSS feed.")
        return

    title = "All Episodes" if show_all else "Available Episodes"
    print(f"Music For Programming - {title}")
    print("=" * (25 + len(title)))

    # Header
    if verbose:
        header = f"{'#':>3}  {'Curator':<20}  {'CUE':>3}  {'FFm':>3}  {'MP3':>3}"
    else:
        header = f"{'#':>3}  {'Curator':<20}  {'Ch':>3}  {'MP3':>3}"

    if include_urls:
        header += "  URL"

    print(header)
    print("-" * len(header) + ("-" * 50 if include_urls else ""))

    for ep in episodes:
        num = ep["number"]
        curator = ep["curator"][:20]  # Truncate long names

        if verbose:
            cue = "yes" if ep["has_cue"] else " - "
            ffm = "yes" if ep["has_ffmeta"] else " - "
            row = f"{num:3d}  {curator:<20}  {cue:>3}  {ffm:>3}"
        else:
            chapters = "yes" if ep["has_chapters"] else " - "
            row = f"{num:3d}  {curator:<20}  {chapters:>3}"

        mp3 = "yes" if ep["has_mp3"] else " - "
        row += f"  {mp3:>3}"

        if include_urls:
            row += f"  {ep['url']}"

        print(row)


def _output_tsv(episodes: list, include_urls: bool, verbose: bool) -> None:
    """Output episodes in TSV format for machine parsing."""
    for ep in episodes:
        fields = [
            str(ep["number"]),
            ep["curator"],
        ]

        if verbose:
            fields.append("cue" if ep["has_cue"] else "-")
            fields.append("ffmeta" if ep["has_ffmeta"] else "-")
        else:
            fields.append("chapters" if ep["has_chapters"] else "-")

        fields.append("local" if ep["has_mp3"] else "-")

        if include_urls:
            fields.append(ep["url"])

        print("\t".join(fields))


def parse_list_args(args: list[str]) -> dict:
    """Parse arguments for the list action."""
    parser = argparse.ArgumentParser(
        prog="mfp-rss-helper list",
        description="List Music For Programming episodes with status",
    )
    parser.add_argument(
        "--format",
        choices=["human", "tsv"],
        default="human",
        help="Output format (default: human)",
    )
    parser.add_argument(
        "--urls",
        action="store_true",
        help="Include download URLs in output",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        dest="show_all",
        help="Show all episodes (default: only those with chapters)",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Show CUE/FFmeta breakdown separately",
    )

    parsed = parser.parse_args(args)
    return {
        "format_type": parsed.format,
        "include_urls": parsed.urls,
        "show_all": parsed.show_all,
        "verbose": parsed.verbose,
    }


def main() -> int:
    if len(sys.argv) < 2:
        print(__doc__.strip())
        return 1

    arg = sys.argv[1]

    # New 'list' action with detailed output
    if arg == "list":
        try:
            opts = parse_list_args(sys.argv[2:])
            list_episodes_detailed(**opts)
            return 0
        except SystemExit as e:
            # argparse called sys.exit() - propagate the exit code
            return e.code if isinstance(e.code, int) else 1

    # Get RSS-based filename for episode
    if arg == "filename":
        if len(sys.argv) < 3:
            print("Usage: mfp-rss-helper filename <episode-number>", file=sys.stderr)
            return 1
        try:
            episode_num = int(sys.argv[2])
            filename_base = get_filename_base(episode_num)
            print(filename_base)
            return 0
        except ValueError as e:
            print(f"Error: {e}", file=sys.stderr)
            return 1
        except RuntimeError as e:
            print(f"Error: {e}", file=sys.stderr)
            return 1

    # Deprecated --list for backwards compatibility
    if arg == "--list":
        list_episodes()
        return 0

    if arg == "--refresh":
        try:
            fetch_rss(force_refresh=True)
            print(f"Cache refreshed: {CACHE_FILE}")
            return 0
        except RuntimeError as e:
            print(f"Error: {e}", file=sys.stderr)
            return 1

    if arg in ("-h", "--help"):
        print(__doc__.strip())
        return 0

    # Assume it's an episode number
    try:
        episode_num = int(arg)
    except ValueError:
        print(f"Error: Invalid episode number: {arg}", file=sys.stderr)
        return 1

    try:
        url = get_episode_url(episode_num)
        print(url)
        return 0
    except (RuntimeError, ValueError) as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
